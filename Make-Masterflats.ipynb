{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Master Flat Frames\n",
    "### MSP, Week of 2.15.2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "\n",
    "# numerical python\n",
    "import numpy as np\n",
    "\n",
    "# file management tools\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# good module for timing tests\n",
    "import time\n",
    "\n",
    "# plotting stuff\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ability to read/write fits files\n",
    "from astropy.io import fits\n",
    "\n",
    "# fancy image combination technique\n",
    "from astropy.stats import sigma_clipping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Make Defintions\n",
    "\n",
    "These are unchanged (though better documented) from previous versions. In order to avoid lots of boilerplate code, I have moved the basic definitions to a new python script, HDI_io.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    read_image\n",
      "    ----------\n",
      "    routine to read in an image and either return\n",
      "    \n",
      "    mosaic==True\n",
      "        single mosaicked, non-overscan frame\n",
      "        \n",
      "    mosaic==False\n",
      "        dictionary of numbered quadrants for overscan operations\n",
      "        \n",
      "        (can later be combined with arrange_quadrants)\n",
      "        \n",
      "        \n",
      "    inputs\n",
      "    ----------\n",
      "    infile         : (string) filename to be read in\n",
      "    mosaic         : (boolean, default=True) if True, returns a single data frame,\n",
      "                     if False, returns a dictionary of the four quadrants\n",
      "    \n",
      "    outputs\n",
      "    ----------\n",
      "    data_quad      : (dictionary or array) if dictionary, keys are [0,1,2,3], each 2056x2048\n",
      "                     corresponding to each quadrant. if array, single 4122x4096 frame\n",
      "    \n",
      "    overscan_quad  : (dictionary) keys are [0,1,2,3], each 2056x2048, corresponding to each quadrant\n",
      "\n",
      "\n",
      "    dependents\n",
      "    ----------\n",
      "    arrange_quadrants : definition to place quadrants in the correct configuration, below\n",
      "\n",
      "    \n",
      "\n",
      "    arrange_quadrants\n",
      "    -----------------\n",
      "    rearrange HDI quadrants to be in the proper configuration\n",
      "    \n",
      "    can be done with or without overscan, in theory.\n",
      "    \n",
      "    inputs\n",
      "    --------\n",
      "    quadrants   : (dictionary) dictionary of the four quadrants, with keys [0,1,2,3]\n",
      "    \n",
      "    outputs\n",
      "    --------\n",
      "    data_array  : (matrix)\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# make the definitions for reading in images accessible in this notebook.\n",
    "from HDI_io import *\n",
    "\n",
    "print(read_image.__doc__)\n",
    "print(arrange_quadrants.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little definition to check that the filter is set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def verify_hdi_filter(infile,des_filter,verbose=False):\n",
    "    '''\n",
    "    verify_filter\n",
    "    ---------------\n",
    "    check that the filter we think is being used IS being used\n",
    "    \n",
    "    inputs\n",
    "    ---------\n",
    "    infile      : (string) filename of image to check\n",
    "    des_filter  : (string) common filter name (see filter_dict below)\n",
    "    verbose     : (boolean, default=False) if True, print reason for failure\n",
    "    \n",
    "    returns\n",
    "    ---------\n",
    "    0,1,2       : (int code) 0=filter matches; 1=filter does not match; 2=one wheel slot not empty\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # specify the filter dictionary; hardcoded because it will not change\n",
    "    filter_dict = {'V':'102',\\\n",
    "               'R':'103',\\\n",
    "               'I':'104',\\\n",
    "               'Ha':'200',\\\n",
    "               'Hao':'204',\\\n",
    "              'empty':['105','106','107','205','206','207']}\n",
    "    \n",
    "    # get the header\n",
    "    phdr = fits.getheader(infile,0)\n",
    "    \n",
    "    # check that a wheel slot is empty\n",
    "    if ((phdr['FILTER1'] not in filter_dict['empty']) & (phdr['FILTER2'] not in filter_dict['empty']) ):\n",
    "        \n",
    "        if verbose:\n",
    "            print('verify_filter: failed with multiple filters.')\n",
    "            \n",
    "        return 2\n",
    "    \n",
    "    # check that filter matches the desired wheel position\n",
    "    elif  (( phdr['FILTER1'] == filter_dict[des_filter]) | ( phdr['FILTER2'] == filter_dict[des_filter]) ):\n",
    "        return 0\n",
    "    \n",
    "    # default to failure mode\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('verify_filter: failed with non-matching filter.')\n",
    "            \n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat-making definitions\n",
    "\n",
    "There are two ways to construct the flat:\n",
    "1. normalizing by the median of the entire image\n",
    "2. normalizing each quadrant by it's own median\n",
    "\n",
    "here is the routine that uses the median of the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_flat_single_median(flat_files,verbose=False,sigma_clip=False,verify=False,filt=''):\n",
    "    '''\n",
    "    make_flat_single_median\n",
    "    -----------------------\n",
    "    routine to take an array of flat files and \n",
    "    1. read in to array\n",
    "    2. subtract overscan from each quadrant\n",
    "    3. normalize by exposure time\n",
    "    4. take the median of the array of images\n",
    "    5. normalize resultant image by *median of entire frame*\n",
    "    \n",
    "    inputs\n",
    "    ------------\n",
    "    flat_files    : (list) input list of images\n",
    "    verbose       : (boolean, default=False) print filter checking (>0) and timing tests (>1)\n",
    "    sigma_clip    : (boolean, default=False) if True, use sigma clipping; else use median\n",
    "    verify        : (boolean, default=False) if True, performs verification of filter wheel position\n",
    "    filt          : (string, default=None) if verify=True, will perform filter comparison\n",
    "    \n",
    "    outputs\n",
    "    ------------\n",
    "    masterflat    : (matrix, 4112x4096) single frame\n",
    "    \n",
    "    '''\n",
    "    if ( (verify)& (filt == '') ):\n",
    "        raise ValueError('verify=True requires filt to be set.')\n",
    "    \n",
    "    t1 = time.time()\n",
    "\n",
    "    # initialize an array for the files\n",
    "    flat = np.zeros([len(flat_files),4112,4096])\n",
    "\n",
    "    # loop through the images\n",
    "    for imgnum,img in enumerate(flat_files):\n",
    "        hdr = fits.getheader(img,0)\n",
    "        \n",
    "        if verify:\n",
    "            code = verify_hdi_filter(img,filt.strip('d'),verbose=verbose)\n",
    "            \n",
    "            if code:\n",
    "                print('make_flat_single_median: skipping bad file {}'.format(img.split('/')[-1]))\n",
    "                continue\n",
    "        \n",
    "        # mosaic=False means that these come out as dictionaries of the extensions\n",
    "        flat_quads,ovrscn = read_image(img,mosaic=False)\n",
    "        \n",
    "        for ext in flat_quads.keys(): \n",
    "            # overscan subtract the quadrants\n",
    "            flat_quads[ext] = flat_quads[ext] - np.median(ovrscn[ext])\n",
    "        \n",
    "        # now arrange the quadrants in the single median version\n",
    "        arranged_flat = arrange_quadrants(flat_quads)\n",
    "            \n",
    "        # also don't forget some twilight flats have different exposure times\n",
    "        flat[imgnum] = arranged_flat/hdr['EXPTIME']\n",
    "            \n",
    "    t2 = time.time()\n",
    "    if (verbose > 1): print('time elapsed to read:',np.round(t2-t1,2),' seconds')    \n",
    "        \n",
    "    if sigma_clip:\n",
    "        clipped_arr = sigma_clipping.sigma_clip(flat,sigma=3,axis=0)\n",
    "        median_clipped_arr = np.ma.median(clipped_arr,axis=0)\n",
    "        masterflat = median_clipped_arr.filled(0.)\n",
    "        \n",
    "    else:\n",
    "        # median and normalize the single-value frame\n",
    "        masterflat = np.median(flat,axis=0)\n",
    "        \n",
    "    masterflat /= np.median(masterflat)\n",
    "             \n",
    "    return masterflat\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up global directory structure\n",
    "\n",
    "indir = '/Volumes/AST337/A341_2018/ObservingRunData/'\n",
    "\n",
    "# shadow directory for reductions\n",
    "reducedir = '/Volumes/AST337/reduced/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Lists\n",
    "\n",
    "These are the flat files from each night to use.\n",
    "\n",
    "This is not the most graceful solution: it relies on specifying the data.\n",
    "\n",
    "Please check your flats and the logs and let me know if there are differences! (or flaws in certain images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# list of files\n",
    "flat_list = {}\n",
    "\n",
    "night = '20180113'\n",
    "cnight = '8130'\n",
    "ext = 'f00.fits'\n",
    "# night 1\n",
    "flat_list[night] = {}\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(739,744)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(746,749)]\n",
    "\n",
    "# the julian day ticked over on this set\n",
    "cnight = '8131'\n",
    "flat_list[night]['Rd'].extend([indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(1,3)])\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(4,9)]\n",
    "flat_list[night]['Had'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(11,16)]\n",
    "flat_list[night]['Haod'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(18,22)]\n",
    "\n",
    "\n",
    "# night 2\n",
    "night = '20180114'\n",
    "cnight = '8132'\n",
    "ext = 'f00.fits'\n",
    "flat_list[night] = {}\n",
    "\n",
    "# these are dome flats\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(10,17)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(19,26)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(27,34)]\n",
    "\n",
    "# these are twilight flats\n",
    "flat_list[night]['V'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(576,581)]\n",
    "flat_list[night]['R'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(582,588)]\n",
    "flat_list[night]['I'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(588,596)]\n",
    "flat_list[night]['Ha'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(597,602)]\n",
    "flat_list[night]['Hao'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(607,612)]\n",
    "\n",
    "\n",
    "# night 3\n",
    "night = '20180115'\n",
    "cnight = '8133'\n",
    "ext = 'f00.fits'\n",
    "flat_list[night] = {}\n",
    "# these are dome flats\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(684,689)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(689,694)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(699,704)]\n",
    "flat_list[night]['Had'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(704,709)]\n",
    "flat_list[night]['Haod'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(710,715)]\n",
    "\n",
    "# these are twilight flats\n",
    "flat_list[night]['V'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(3,9)]\n",
    "flat_list[night]['R'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(15,19)]\n",
    "flat_list[night]['I'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(9,15)]\n",
    "\n",
    "\n",
    "# night 4\n",
    "night = '20180116'\n",
    "cnight = '8134'\n",
    "ext = 'f00.fits.gz'\n",
    "flat_list[night] = {}\n",
    "# these are dome flats\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(679,684)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(685,690)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(690,695)]\n",
    "flat_list[night]['Had'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(668,673)]\n",
    "flat_list[night]['Haod'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(674,679)]\n",
    "\n",
    "\n",
    "# night 5\n",
    "night = '20180117'\n",
    "cnight = '8135'\n",
    "ext = 'f00.fits'\n",
    "flat_list[night] = {}\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(2,14)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(16,28)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(28,40)]\n",
    "flat_list[night]['Had'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(42,53)]\n",
    "flat_list[night]['Haod'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(56,68)]\n",
    "\n",
    "\n",
    "# night 6\n",
    "night = '20180118'\n",
    "cnight = '8136'\n",
    "ext = 'f00.fits'\n",
    "flat_list[night] = {}\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(2,7)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(8,13)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(14,18)]\n",
    "\n",
    "# twilight flats\n",
    "flat_list[night]['V'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(19,23)]\n",
    "flat_list[night]['R'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(23,29)]\n",
    "flat_list[night]['I'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(30,36)]\n",
    "flat_list[night]['Ha'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(804,809)]\n",
    "flat_list[night]['Hao'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(812,815)]\n",
    "flat_list[night]['Hao'].extend([indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(818,820)])\n",
    "\n",
    "\n",
    "# night 7\n",
    "night = '20180119'\n",
    "cnight = '8137'\n",
    "ext = 'f00.fits.gz'\n",
    "flat_list[night] = {}\n",
    "flat_list[night]['Vd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(2,7)]\n",
    "flat_list[night]['Rd'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(7,12)]\n",
    "flat_list[night]['Id'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(12,17)]\n",
    "flat_list[night]['Had'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(17,23)]\n",
    "flat_list[night]['Haod'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(24,29)]\n",
    "\n",
    "# twilight flats\n",
    "flat_list[night]['V'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(44,47)]\n",
    "flat_list[night]['V'].extend([indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(819,824)])\n",
    "flat_list[night]['R'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(38,41)]\n",
    "flat_list[night]['R'].extend([indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(834,839)])\n",
    "flat_list[night]['I'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(29,34)]\n",
    "flat_list[night]['I'].extend([indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(846,853)])\n",
    "flat_list[night]['Ha'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(853,858)]\n",
    "flat_list[night]['Hao'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(858,865)]\n",
    "\n",
    "\n",
    "\n",
    "# night 8\n",
    "night = '20180120'\n",
    "cnight = '8138'\n",
    "ext = 'f00.fits.gz'\n",
    "flat_list[night] = {}\n",
    "flat_list[night]['V'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(25,35)]\n",
    "flat_list[night]['R'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(35,41)]\n",
    "flat_list[night]['I'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(41,47)]\n",
    "flat_list[night]['Ha'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(12,17)]\n",
    "flat_list[night]['Hao'] = [indir+night+'/c'+cnight+'t0{0:03d}'.format(x)+ext for x in range(17,23)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nights are split into different folders\n",
    "datadirs = ['20180113','20180114','20180115','20180116','20180117','20180118','20180119','20180120']\n",
    "\n",
    "# which filters. appended 'd' means dome flat, otherwise they are twilights\n",
    "filters = ['Vd','Rd','Id','Had','Haod','V','R','I','Ha','Hao']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Loops\n",
    "\n",
    "Loops for\n",
    "1. Night\n",
    "2. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180113\n",
      "time elapsed to make flat: 70.47  seconds\n",
      "time elapsed to make flat: 68.95  seconds\n",
      "time elapsed to make flat: 66.32  seconds\n",
      "time elapsed to make flat: 68.62  seconds\n",
      "time elapsed to make flat: 62.06  seconds\n",
      "time elapsed for 20180113 flats: 5.6  minutes\n",
      "20180114\n",
      "time elapsed to make flat: 98.24  seconds\n",
      "time elapsed to make flat: 94.66  seconds\n",
      "time elapsed to make flat: 100.62  seconds\n",
      "time elapsed to make flat: 68.95  seconds\n",
      "time elapsed to make flat: 79.83  seconds\n",
      "time elapsed to make flat: 111.52  seconds\n",
      "time elapsed to make flat: 65.21  seconds\n",
      "time elapsed to make flat: 66.2  seconds\n",
      "time elapsed for 20180114 flats: 11.4  minutes\n",
      "20180115\n",
      "time elapsed to make flat: 71.42  seconds\n",
      "time elapsed to make flat: 69.73  seconds\n",
      "time elapsed to make flat: 82.03  seconds\n",
      "time elapsed to make flat: 84.26  seconds\n",
      "time elapsed to make flat: 77.32  seconds\n",
      "time elapsed to make flat: 88.6  seconds\n",
      "time elapsed to make flat: 66.81  seconds\n",
      "time elapsed to make flat: 86.48  seconds\n",
      "time elapsed for 20180115 flats: 10.4  minutes\n",
      "20180116\n",
      "time elapsed to make flat: 80.22  seconds\n",
      "time elapsed to make flat: 84.71  seconds\n",
      "time elapsed to make flat: 87.01  seconds\n",
      "time elapsed to make flat: 87.04  seconds\n",
      "time elapsed to make flat: 79.78  seconds\n",
      "time elapsed for 20180116 flats: 7.0  minutes\n",
      "20180117\n",
      "time elapsed to make flat: 180.5  seconds\n",
      "time elapsed to make flat: 190.27  seconds\n",
      "time elapsed to make flat: 187.15  seconds\n",
      "time elapsed to make flat: 179.58  seconds\n",
      "time elapsed to make flat: 185.15  seconds\n",
      "time elapsed for 20180117 flats: 15.4  minutes\n",
      "20180118\n",
      "time elapsed to make flat: 68.17  seconds\n",
      "time elapsed to make flat: 65.04  seconds\n",
      "time elapsed to make flat: 55.28  seconds\n",
      "time elapsed to make flat: 54.22  seconds\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8136t0029f00.fits\n",
      "time elapsed to make flat: 80.31  seconds\n",
      "time elapsed to make flat: 71.12  seconds\n",
      "time elapsed to make flat: 61.99  seconds\n",
      "time elapsed to make flat: 62.66  seconds\n",
      "time elapsed for 20180118 flats: 8.6  minutes\n",
      "20180119\n",
      "time elapsed to make flat: 72.09  seconds\n",
      "time elapsed to make flat: 72.14  seconds\n",
      "time elapsed to make flat: 71.9  seconds\n",
      "time elapsed to make flat: 80.42  seconds\n",
      "time elapsed to make flat: 71.76  seconds\n",
      "time elapsed to make flat: 97.8  seconds\n",
      "time elapsed to make flat: 99.15  seconds\n",
      "time elapsed to make flat: 146.92  seconds\n",
      "time elapsed to make flat: 68.07  seconds\n",
      "time elapsed to make flat: 86.09  seconds\n",
      "time elapsed for 20180119 flats: 14.4  minutes\n",
      "20180120\n",
      "time elapsed to make flat: 133.28  seconds\n",
      "time elapsed to make flat: 78.01  seconds\n",
      "time elapsed to make flat: 78.07  seconds\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0012f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0013f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0014f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0015f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0016f00.fits.gz\n",
      "time elapsed to make flat: 58.17  seconds\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0017f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0018f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0019f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0020f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0021f00.fits.gz\n",
      "verify_filter: failed with non-matching filter.\n",
      "make_flat_single_median: skipping bad file c8138t0022f00.fits.gz\n",
      "time elapsed to make flat: 65.01  seconds\n",
      "time elapsed for 20180120 flats: 6.9  minutes\n",
      "time elapsed for ALL flats: 79.8  minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tt = time.time()\n",
    "\n",
    "# loop through nights of data\n",
    "for night in datadirs:\n",
    "    print(night)\n",
    "    \n",
    "    tn = time.time()\n",
    "    \n",
    "    for filter in filters:\n",
    "        \n",
    "        # check which sets of flats are actually defined for a given night\n",
    "        if filter not in flat_list[night].keys():\n",
    "            continue\n",
    "        \n",
    "        flat_files = flat_list[night][filter]\n",
    "    \n",
    "        t0 = time.time()\n",
    "\n",
    "        # this is the entire flat maker, given a set of flat files\n",
    "        # note that I have sigma clipping on here--this is SLOW!\n",
    "        masterflat = make_flat_single_median(flat_files,verbose=1,sigma_clip=True,verify=True,filt=filter)\n",
    "        \n",
    "        phdr = fits.getheader(flat_files[0],0)\n",
    "        fits.writeto(reducedir+night+'/masterflat_{}.fits'.format(filter),masterflat,phdr,overwrite=True)\n",
    "        \n",
    "        # be obsessive about timing\n",
    "        t3 = time.time()\n",
    "        print('time elapsed to make flat:',np.round(t3-t0,2),' seconds')\n",
    "        \n",
    "    # be more obsessive about timing\n",
    "    print('time elapsed for {} flats:'.format(night),np.round((time.time()-tn)/60.,1),' minutes',end='\\n\\n')\n",
    "\n",
    "# one more timing test\n",
    "print('time elapsed for ALL flats:',np.round((time.time()-tt)/60.,1),' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
